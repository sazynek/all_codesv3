from .db_init import Base  # type: ignore
from sqlalchemy.orm import Mapped, mapped_column
from sqlalchemy import select, and_, func, select, delete, update
from typing import Any, Sequence
from sqlalchemy import func  # –î–æ–±–∞–≤—å—Ç–µ —ç—Ç–æ—Ç –∏–º–ø–æ—Ä—Ç
from sqlalchemy.ext.asyncio import AsyncSession

# from typing import Optional


class PromptData(Base):
    __tablename__ = "taxi"
    id: Mapped[int] = mapped_column(primary_key=True, index=True, unique=True)

    text: Mapped[str] = mapped_column(index=True)


class Anecdote(Base):
    __tablename__ = "anecdotes"
    id: Mapped[int] = mapped_column(primary_key=True, index=True, unique=True)

    text: Mapped[str]
    time_to_start: Mapped[str]  # mb change data


class User(Base):
    __tablename__ = "users"
    id: Mapped[int] = mapped_column(primary_key=True, index=True, unique=True)
    tg_id: Mapped[int]  # change to BigInt

    text: Mapped[str]
    time_to_delete: Mapped[str]  # mb change data


class AdministerData(Base):
    __tablename__ = "administers"
    id: Mapped[int] = mapped_column(primary_key=True, index=True, unique=True)

    tabu: Mapped[list[str]]


class ParserUrl(Base):
    __tablename__ = "administers"
    id: Mapped[int] = mapped_column(primary_key=True, index=True, unique=True)

    url: Mapped[str]
    content: Mapped[str | None]


class Chats(Base):
    __tablename__ = "chats"
    id: Mapped[int] = mapped_column(primary_key=True, index=True, unique=True)

    chat: Mapped[str]


class Advertisement(Base):
    __tablename__ = "advertisements"
    id: Mapped[int] = mapped_column(primary_key=True, index=True, unique=True)

    text: Mapped[str]


# async def find_similar_taxis_db(
#     session: AsyncSession,
#     lvl: Optional[str] = None,
#     city: Optional[str] = None,
#     car: Optional[str] = None,
#     year: Optional[int] = None,
# ) -> Sequence[Taxi]:
#     """
#     –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Ç–∞–∫—Å–∏ —á–µ—Ä–µ–∑ –ë–î —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π —Ä–µ–≥–∏—Å—Ç—Ä–∞ –∏ –æ–±—Ä–µ–∑–∞–Ω–∏–µ–º –æ–∫–æ–Ω—á–∞–Ω–∏–π

#     Args:
#         session: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Å–µ—Å—Å–∏—è –ë–î
#         lvl: –£—Ä–æ–≤–µ–Ω—å —Ç–∞–∫—Å–∏ (LIKE –ø–æ–∏—Å–∫, –æ–±—Ä–µ–∑–∞—é—Ç—Å—è –æ–∫–æ–Ω—á–∞–Ω–∏—è)
#         city: –ì–æ—Ä–æ–¥ (LIKE –ø–æ–∏—Å–∫, –æ–±—Ä–µ–∑–∞—é—Ç—Å—è –æ–∫–æ–Ω—á–∞–Ω–∏—è)
#         car: –ú–∞—à–∏–Ω–∞ (LIKE –ø–æ–∏—Å–∫, –æ–±—Ä–µ–∑–∞—é—Ç—Å—è –æ–∫–æ–Ω—á–∞–Ω–∏—è)
#         year: –ì–æ–¥ –≤—ã–ø—É—Å–∫–∞ (—É–∫–∞–∑–∞–Ω–Ω—ã–π_–≥–æ–¥ >= –≥–æ–¥–∞_–≤_–±–¥)

#     Returns:
#         List[Taxi]: –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç–∞–∫—Å–∏
#     """

#     def normalize_like_param(text: str) -> str:
#         """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è LIKE –ø–æ–∏—Å–∫–∞: –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä + –æ–±—Ä–µ–∑–∞–Ω–∏–µ"""
#         if not text:
#             return text

#         # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
#         text_lower = text.strip().lower()

#         # –û–±—Ä–µ–∑–∞–µ–º –æ–∫–æ–Ω—á–∞–Ω–∏–µ –¥–ª—è LIKE –ø–æ–∏—Å–∫–∞
#         return shorten_for_like(text_lower)

#     def shorten_for_like(text: str) -> str:
#         """–û–±—Ä–µ–∑–∞–µ—Ç –æ–∫–æ–Ω—á–∞–Ω–∏–µ (–¥–æ 2 —Å–∏–º–≤–æ–ª–æ–≤) –¥–ª—è –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ LIKE –ø–æ–∏—Å–∫–∞"""
#         if not text or len(text) <= 6:
#             return text
#         # –û–±—Ä–µ–∑–∞–µ–º 1-2 —Å–∏–º–≤–æ–ª–∞ —Å –∫–æ–Ω—Ü–∞, –µ—Å–ª–∏ —ç—Ç–æ –±—É–∫–≤—ã
#         if text[-1].isalpha() and text[-2].isalpha():
#             return text[:-2]
#         elif text[-1].isalpha():
#             return text[:-1]
#         return text

#     conditions: list[Any] = []
#     search_params: dict[str, Any] = {}

#     # 1. –§–∏–ª—å—Ç—Ä –ø–æ –≥–æ–¥—É: year >= Taxi.year
#     if year is not None:
#         conditions.append(year >= Taxi.year)
#         search_params["year"] = year
#         print(f"‚úÖ –§–∏–ª—å—Ç—Ä –ø–æ –≥–æ–¥—É: {year} >= taxi.year")

#     # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –ø–æ–∏—Å–∫ –ø–æ –æ—Å—Ç–∞–ª—å–Ω—ã–º –ø–æ–ª—è–º (–ø–æ–ª–Ω–æ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É)
#     if lvl:
#         lvl_normalized = normalize_like_param(lvl)
#         # –ü—Ä–∏–≤–æ–¥–∏–º –æ–±–∞ –∑–Ω–∞—á–µ–Ω–∏—è –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É: func.lower(Taxi.lvl)
#         conditions.append(func.lower(Taxi.lvl).like(f"%{lvl_normalized}%"))
#         search_params["lvl"] = lvl
#         search_params["lvl_normalized"] = lvl_normalized
#         print(f"üîç –ü–æ–∏—Å–∫ –ø–æ lvl: '{lvl}' ‚Üí lower(lvl) LIKE '%{lvl_normalized}%'")

#     if city:
#         city_normalized = normalize_like_param(city)
#         # –ü—Ä–∏–≤–æ–¥–∏–º –ø–æ–ª–µ city –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
#         conditions.append(func.lower(Taxi.city).like(f"%{city_normalized}%"))
#         search_params["city"] = city
#         search_params["city_normalized"] = city_normalized
#         print(f"üèôÔ∏è –ü–æ–∏—Å–∫ –ø–æ city: '{city}' ‚Üí lower(city) LIKE '%{city_normalized}%'")

#     if car:
#         car_normalized = normalize_like_param(car)
#         # –ü—Ä–∏–≤–æ–¥–∏–º –ø–æ–ª–µ car –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
#         conditions.append(func.lower(Taxi.car).like(f"%{car_normalized}%"))
#         search_params["car"] = car
#         search_params["car_normalized"] = car_normalized
#         print(f"üöó –ü–æ–∏—Å–∫ –ø–æ car: '{car}' ‚Üí lower(car) LIKE '%{car_normalized}%'")

#     # 3. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ–∏—Å–∫–∞
#     if search_params:
#         print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞: {search_params}")

#     # 4. –°—Ç—Ä–æ–∏–º –∑–∞–ø—Ä–æ—Å
#     if conditions:
#         stmt = select(Taxi).where(and_(*conditions))
#     else:
#         stmt = select(Taxi)

#     # 5. –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
#     result = await session.execute(stmt)
#     taxis = result.scalars().all()

#     print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ç–∞–∫—Å–∏: {len(taxis)}")
#     return taxis
