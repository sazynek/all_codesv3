# import requests


from typing import Any
from bs4 import BeautifulSoup as soup

# text
import html2text

# selenium
from selenium import webdriver
from selenium.webdriver.common.by import By

# from selenium.webdriver.remote.webelement import WebElement

options = webdriver.ChromeOptions()
# options.add_argument("--headless=new")  # The recommended new headless mode
options.add_argument("--disable-gpu")

service = webdriver.ChromeService()


def get_selenium_html(url: str) -> str:

    driver = webdriver.Chrome(options=options, service=service)
    # driver = webdriver.Chrome()

    # driver.ge
    driver.get(url)

    d = driver.page_source
    driver.quit()
    return d


def parser_by_url(url: str):

    text = get_selenium_html(url)
    # print(f"raw {text}")
    parse_html2text(text)


def parse_html2text(text: str) -> str:
    h = html2text.HTML2Text()
    h.ignore_links = True  # ÐÐµ Ð²Ñ‹Ð²Ð¾Ð´Ð¸Ñ‚ÑŒ ÑÑÑ‹Ð»ÐºÐ¸
    h.ignore_images = True  # ÐÐµ Ð²Ñ‹Ð²Ð¾Ð´Ð¸Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
    h.ignore_tables = True  # Ð˜Ð³Ð½Ð¾Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ (Ð¸Ð»Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ bypass_tables)
    h.ignore_emphasis = False  # Ð Ð°ÑÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ ÑƒÐ±Ñ€Ð°Ñ‚ÑŒ **Ð¶Ð¸Ñ€Ð½Ñ‹Ð¹** Ð¸ _ÐºÑƒÑ€ÑÐ¸Ð²_
    h.unicode_snob = True  # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ "ÑƒÐ¼Ð½Ñ‹Ðµ" ÐºÐ°Ð²Ñ‹Ñ‡ÐºÐ¸ Ð¸ Ñ‚Ð¸Ñ€Ðµ

    # print("RAW ", text)
    s = soup(text, "lxml")
    res = s.select_one("html body")
    # print("AFTER PARSE", res)
    if res is not None:
        html = res.prettify()
        # print(html)
        # print(html)
        text = h.handle(html)
    return text


import time


def parse_tariff_ya(url: str = "https://taxi.yandex.ru/spb/tariff/"):

    driver = webdriver.Chrome(options=options, service=service)

    driver.get(url)
    elements = driver.find_elements(
        By.CSS_SELECTOR,
        ".HorizTabs a",
    )
    links_data: list[dict[str, str]] = []  # type: ignore
    for elem in elements:
        href: str | None = elem.get_attribute("href")  # type: ignore
        text: str = elem.text  # type: ignore
        # assert isinstance(text, str)
        if href is not None:  # type: ignore
            links_data.append({"href": href, "text": text})  # type: ignore

    time.sleep(2)
    for i in links_data:  # type: ignore
        if i.get("href", None):  # type: ignore
            driver.get(i["href"])  # type: ignore
            time.sleep(1)
            page_content = driver.page_source
            s = soup(page_content, "lxml")
            res = s.select_one("html body main")
            if res is not None:
                res = res.select_one(".TariffDetails__main-price")
                if res:
                    res = res.prettify()
                    print("=" * 90, "\n")
                    str = parse_html2text(res)

                    res = i["text"] + "\n" + str
                    print(res)
                    print("=" * 90, "\n")


def parse_parks_ya(url: str = "https://taxi.yandex.ru/spb/parks") -> str:

    driver = webdriver.Chrome(options=options, service=service)

    driver.get(url)
    infinite_scroll(driver)

    elements = driver.find_elements(
        By.CSS_SELECTOR,
        "div.Park:nth-child > a:nth-child(1)",
    )
    links_data: list[Any] = []
    for elem in elements:
        href: str | None = elem.get_attribute("href")  # type: ignore
        if href:
            links_data.append(href)  # type: ignore

    time.sleep(2)
    for href in links_data:
        if href:
            driver.get(href)
            time.sleep(1)
            page_content = driver.page_source
            s = soup(page_content, "lxml")
            res = s.select_one("html body main")
            if res is not None:
                res = res.select_one(".ParkDetails__content")
                if res is not None:

                    res_header = res.select_one(".ParkDetails__header")
                    tariff = res.select_one("#react-select-tariffSelect--value-item")

                    price_group = res.select_one(".PriceGroup")

                    res = res.prettify()
                    print("=" * 90, "\n")
                    parse_html2text(res)
                    print("=" * 90, "\n")
    return ""


# @delete


def infinite_scroll(driver: webdriver.Chrome, scroll_delay: int = 1):
    """
    ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ð±ÐµÑÐºÐ¾Ð½ÐµÑ‡Ð½Ð°Ñ Ð¿Ñ€Ð¾ÐºÑ€ÑƒÑ‚ÐºÐ° ReactVirtualized ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ð°
    """

    container = driver.find_element(
        By.CSS_SELECTOR,
        "#application > div.Core > div > main > div.Parks__content > aside > div > div.ParkList__list-wrap > div:nth-child(1) > div",
    )

    print("ðŸŒ€ ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽ Ð±ÐµÑÐºÐ¾Ð½ÐµÑ‡Ð½ÑƒÑŽ Ð¿Ñ€Ð¾ÐºÑ€ÑƒÑ‚ÐºÑƒ...")
    print("ÐÐ°Ð¶Ð¼Ð¸Ñ‚Ðµ Ctrl+C Ð² Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð°Ð»Ðµ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ")

    scroll_count = 0
    last_height = 0
    # div.Park:nth-child(6) > a:nth-child(1)
    try:
        while True:
            scroll_count += 1

            # ÐŸÑ€Ð¾ÐºÑ€ÑƒÑ‡Ð¸Ð²Ð°ÐµÐ¼ Ð² ÑÐ°Ð¼Ñ‹Ð¹ Ð½Ð¸Ð·
            driver.execute_script(  # type: ignore
                "arguments[0].scrollTop = arguments[0].scrollHeight;", container
            )

            print(f"ðŸ“œ ÐŸÑ€Ð¾ÐºÑ€ÑƒÑ‚ÐºÐ° #{scroll_count}")
            time.sleep(scroll_delay)
            current_height = driver.execute_script(  # type: ignore
                "return arguments[0].scrollHeight;", container
            )

            if current_height > last_height:
                print(f"   Ð’Ñ‹ÑÐ¾Ñ‚Ð° ÑƒÐ²ÐµÐ»Ð¸Ñ‡Ð¸Ð»Ð°ÑÑŒ: {last_height} â†’ {current_height}")
                last_height = current_height
            else:
                break

    except KeyboardInterrupt:
        print(f"\nâ¹ï¸  ÐŸÑ€Ð¾ÐºÑ€ÑƒÑ‚ÐºÐ° Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼")
        print(f"Ð’ÑÐµÐ³Ð¾ Ð¿Ñ€Ð¾ÐºÑ€ÑƒÑ‚Ð¾Ðº: {scroll_count}")
        print(f"Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ð°Ñ Ð²Ñ‹ÑÐ¾Ñ‚Ð°: {last_height}")


def parse_knowledge_base_ya(
    url: str = "https://pro.yandex.ru/ru-ru/knowledge-base",
):

    driver = webdriver.Chrome(options=options, service=service)

    driver.get(url)
    infinite_scroll(driver)

    elements = driver.find_elements(
        By.CSS_SELECTOR,
        "div.profession_professionItem__25iWE > div > a",
    )
    links_data: list[Any] = []
    for elem in elements:
        href: str | None = elem.get_attribute("href")  # type: ignore
        if href:
            links_data.append(href)  # type: ignore

    # time.sleep(2)
    # for href in links_data:
    #     if href:
    #         driver.get(href)
    #         time.sleep(1)
    #         page_content = driver.page_source
    #         s = soup(page_content, "lxml")
    #         res = s.select_one("html body main")
    #         if res is not None:
    #             res = res.select_one(".ParkDetails__content")
    #             if res is not None:

    #                 res_header = res.select_one(".ParkDetails__header")
    #                 tariff = res.select_one("#react-select-tariffSelect--value-item")

    #                 price_group = res.select_one(".PriceGroup")

    #                 res = res.prettify()
    #                 print("=" * 90, "\n")
    #                 parse_html2text(res)
    #                 print("=" * 90, "\n")


# @delete

parse_knowledge_base_ya()
# parse_tariff_ya()
# parse_parks_ya()

# parser_by_url("https://taxi.yandex.ru/spb/parks")


# parser_by_url("https://pro.yandex.ru/ru-ru/knowledge-base")
# parser_by_url("https://pikabu.ru/community/taxi")

# parser_by_url("https://web.telegram.org/#@igormylnikovchannelchat")

# https://t.me/igormylnikovchannelchat
