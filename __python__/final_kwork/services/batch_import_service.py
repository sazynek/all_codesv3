"""
–°–µ—Ä–≤–∏—Å –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞ —Å–µ—Å—Å–∏–π –∏–∑ ZIP-–∞—Ä—Ö–∏–≤–∞.

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
- –ò–º–ø–æ—Ä—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö .session —Ñ–∞–π–ª–æ–≤ –∏–∑ –æ–¥–Ω–æ–≥–æ ZIP
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ JSON —Å api_id/api_hash —Ä—è–¥–æ–º —Å –∫–∞–∂–¥–æ–π —Å–µ—Å—Å–∏–µ–π
- –†–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã JSON (–ø–ª–æ—Å–∫–∏–π, –≤–ª–æ–∂–µ–Ω–Ω—ã–π, —Ä–∞–∑–Ω—ã–µ –∫–ª—é—á–∏)
- –û—Ç—á—ë—Ç –æ–± –∏–º–ø–æ—Ä—Ç–µ —Å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π
"""

import json
import logging
import os
import shutil
import uuid
import zipfile
from dataclasses import dataclass, field
from typing import List, Optional, Tuple

from sqlalchemy.ext.asyncio import AsyncSession

from config import settings
from db.models import Account, AccountStatus, StorageType
from services.session_import_service import (
    INBOX_DIR,
    SESSIONS_DIR,
    ensure_directories,
    validate_session,
    check_duplicate,
    extract_api_credentials_from_dict,
)
from services import proxy_service

logger = logging.getLogger(__name__)

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä ZIP (500 MB)
MAX_ZIP_SIZE = 500 * 1024 * 1024


@dataclass
class SessionImportItem:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∏–º–ø–æ—Ä—Ç–∞ –æ–¥–Ω–æ–π —Å–µ—Å—Å–∏–∏."""

    session_path: str
    session_name: str
    success: bool
    account_id: Optional[int] = None
    tg_user_id: Optional[int] = None
    username: Optional[str] = None
    phone: Optional[str] = None
    api_id: Optional[int] = None
    api_hash_masked: Optional[str] = None
    api_source: str = "none"  # "json", "env", "none"
    error: Optional[str] = None
    is_duplicate: bool = False


@dataclass
class BatchImportReport:
    """–û—Ç—á—ë—Ç –æ –ø–∞–∫–µ—Ç–Ω–æ–º –∏–º–ø–æ—Ä—Ç–µ."""

    total_sessions_found: int = 0
    successfully_imported: int = 0
    with_api_credentials: int = 0
    with_env_fallback: int = 0
    duplicates_skipped: int = 0
    errors: int = 0
    items: List[SessionImportItem] = field(default_factory=list)

    def add_success(self, item: SessionImportItem):
        """–î–æ–±–∞–≤–∏—Ç—å —É—Å–ø–µ—à–Ω—ã–π –∏–º–ø–æ—Ä—Ç."""
        self.items.append(item)
        self.successfully_imported += 1
        if item.api_source == "json":
            self.with_api_credentials += 1
        elif item.api_source == "env":
            self.with_env_fallback += 1

    def add_error(self, item: SessionImportItem):
        """–î–æ–±–∞–≤–∏—Ç—å –æ—à–∏–±–∫—É."""
        self.items.append(item)
        if item.is_duplicate:
            self.duplicates_skipped += 1
        else:
            self.errors += 1

    def format_message(self) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á—ë—Ç–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤ —á–∞—Ç."""
        lines = [
            "üì¶ **–û—Ç—á—ë—Ç –∏–º–ø–æ—Ä—Ç–∞ ZIP**\n",
            f"üìä –ù–∞–π–¥–µ–Ω–æ —Å–µ—Å—Å–∏–π: {self.total_sessions_found}",
            f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {self.successfully_imported}",
            f"üîë –° API –∏–∑ JSON: {self.with_api_credentials}",
            f"‚öôÔ∏è Fallback –Ω–∞ .env.example: {self.with_env_fallback}",
        ]

        if self.duplicates_skipped > 0:
            lines.append(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {self.duplicates_skipped}")

        if self.errors > 0:
            lines.append(f"‚ùå –û—à–∏–±–æ–∫: {self.errors}")

        # –î–µ—Ç–∞–ª–∏ —É—Å–ø–µ—à–Ω—ã—Ö
        if self.successfully_imported > 0:
            lines.append("\n**–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç—ã:**")
            for item in self.items:
                if item.success:
                    api_mark = "üîë" if item.api_source == "json" else "‚öôÔ∏è"
                    username_str = f"@{item.username}" if item.username else ""
                    lines.append(
                        f"‚Ä¢ #{item.account_id} {username_str} "
                        f"`{item.phone or item.tg_user_id or 'N/A'}` {api_mark}"
                    )

        # –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–æ–∫
        error_items = [i for i in self.items if not i.success and not i.is_duplicate]
        if error_items:
            lines.append("\n**–û—à–∏–±–∫–∏:**")
            for item in error_items[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –æ—à–∏–±–æ–∫
                lines.append(f"‚Ä¢ `{item.session_name}`: {item.error}")
            if len(error_items) > 5:
                lines.append(f"  ... –∏ –µ—â—ë {len(error_items) - 5} –æ—à–∏–±–æ–∫")

        # –î—É–±–ª–∏–∫–∞—Ç—ã
        dup_items = [i for i in self.items if i.is_duplicate]
        if dup_items:
            lines.append(f"\n**–î—É–±–ª–∏–∫–∞—Ç—ã (–ø—Ä–æ–ø—É—â–µ–Ω—ã):** {len(dup_items)} —à—Ç.")

        return "\n".join(lines)


def extract_zip(zip_path: str, dst_dir: str) -> Tuple[bool, str]:
    """
    –†–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å ZIP-–∞—Ä—Ö–∏–≤.

    Args:
        zip_path: –ü—É—Ç—å –∫ ZIP —Ñ–∞–π–ª—É
        dst_dir: –¶–µ–ª–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è

    Returns:
        (success, error_message)
    """
    try:
        os.makedirs(dst_dir, exist_ok=True)

        with zipfile.ZipFile(zip_path, "r") as zf:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ ZIP bomb
            total_size = sum(info.file_size for info in zf.infolist())
            if total_size > MAX_ZIP_SIZE * 10:
                return (
                    False,
                    f"–ê—Ä—Ö–∏–≤ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –ø–æ—Å–ª–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ ({total_size // 1024 // 1024} MB)",
                )

            zf.extractall(dst_dir)

        return True, ""

    except zipfile.BadZipFile:
        return False, "–ü–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω—ã–π ZIP-–∞—Ä—Ö–∏–≤"
    except Exception as e:
        return False, f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏: {e}"


def find_session_files(root_dir: str) -> List[str]:
    """
    –ù–∞–π—Ç–∏ –≤—Å–µ .session —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (—Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ).

    Args:
        root_dir: –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞

    Returns:
        –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ .session —Ñ–∞–π–ª–∞–º
    """
    session_files = []

    for dirpath, dirnames, filenames in os.walk(root_dir):
        for filename in filenames:
            if filename.lower().endswith(".session"):
                session_files.append(os.path.join(dirpath, filename))

    return session_files


def find_matching_json(session_path: str) -> Optional[str]:
    """
    –ù–∞–π—Ç–∏ JSON —Ñ–∞–π–ª —Å api_id/api_hash –¥–ª—è –¥–∞–Ω–Ω–æ–π —Å–µ—Å—Å–∏–∏.

    –°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–æ–∏—Å–∫–∞:
    1. –§–∞–π–ª —Å —Ç–µ–º –∂–µ –∏–º–µ–Ω–µ–º: name.session -> name.json
    2. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∏–º–µ–Ω–∞ –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ: api.json, config.json, etc.
    3. –õ—é–±–æ–π .json –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ credentials

    Args:
        session_path: –ü—É—Ç—å –∫ .session —Ñ–∞–π–ª—É

    Returns:
        –ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É –∏–ª–∏ None
    """
    session_dir = os.path.dirname(session_path)
    session_basename = os.path.splitext(os.path.basename(session_path))[0]

    # 1. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–º–µ–Ω–∏: name.session -> name.json
    matching_json = os.path.join(session_dir, f"{session_basename}.json")
    if os.path.exists(matching_json):
        return matching_json

    # 2. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∏–º–µ–Ω–∞
    priority_names = settings.account_json_filenames_list
    for name in priority_names:
        json_path = os.path.join(session_dir, name)
        if os.path.exists(json_path):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ JSON —Å–æ–¥–µ—Ä–∂–∏—Ç credentials
            creds = extract_api_credentials(json_path)
            if creds:
                return json_path

    # 3. –õ—é–±–æ–π .json —Ñ–∞–π–ª —Å credentials
    try:
        for filename in os.listdir(session_dir):
            if filename.lower().endswith(".json"):
                json_path = os.path.join(session_dir, filename)
                creds = extract_api_credentials(json_path)
                if creds:
                    return json_path
    except OSError:
        pass

    return None


def extract_api_credentials(json_path: str) -> Optional[Tuple[int, str]]:
    """
    –ò–∑–≤–ª–µ—á—å api_id –∏ api_hash –∏–∑ JSON —Ñ–∞–π–ª–∞.

    Args:
        json_path: –ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É

    Returns:
        (api_id, api_hash) –∏–ª–∏ None
    """
    try:
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return extract_api_credentials_from_dict(data)
    except json.JSONDecodeError as e:
        logger.warning(f"Invalid JSON in {json_path}: {e}")
        return None
    except Exception as e:
        logger.warning(f"Failed to read {json_path}: {e}")
        return None


def mask_api_hash(api_hash: str) -> str:
    """–ú–∞—Å–∫–∏—Ä–æ–≤–∞—Ç—å api_hash –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    if not api_hash or len(api_hash) < 8:
        return "***"
    return f"{api_hash[:4]}...{api_hash[-4:]}"


async def import_one_session(
    db_session: AsyncSession,
    session_path: str,
    api_id: Optional[int] = None,
    api_hash: Optional[str] = None,
    api_source: str = "none",
) -> SessionImportItem:
    """
    –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–¥–Ω—É —Å–µ—Å—Å–∏—é.

    Args:
        db_session: SQLAlchemy async session
        session_path: –ü—É—Ç—å –∫ .session —Ñ–∞–π–ª—É
        api_id: API ID (–µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω –≤ JSON)
        api_hash: API Hash (–µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω –≤ JSON)
        api_source: –ò—Å—Ç–æ—á–Ω–∏–∫ credentials ("json", "env", "none")

    Returns:
        SessionImportItem —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
    """
    session_name = os.path.splitext(os.path.basename(session_path))[0]

    item = SessionImportItem(
        session_path=session_path,
        session_name=session_name,
        success=False,
        api_source=api_source,
    )

    # –ï—Å–ª–∏ –Ω–µ—Ç credentials –∏ —Ä–∞–∑—Ä–µ—à—ë–Ω fallback
    if api_id is None or api_hash is None:
        if settings.fallback_env_api and settings.api_id and settings.api_hash:
            api_id = settings.api_id
            api_hash = settings.api_hash
            item.api_source = "env"
        else:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–µ–∑ credentials (fallback –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏)
            item.api_source = "none"

    if api_id:
        item.api_id = api_id
    if api_hash:
        item.api_hash_masked = mask_api_hash(api_hash)

    try:
        logger.info(f"Validating session: {session_path}")

        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Å–µ—Å—Å–∏—é —Å credentials
        # skip_connect=True ‚Äî –ù–ï –ø–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Telegram, —Ç–æ–ª—å–∫–æ —á–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞
        # –≠—Ç–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ: –Ω–µ —É–±–∏–≤–∞–µ–º —Å–µ—Å—Å–∏—é –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
        validation = await validate_session(
            session_path, api_id=api_id, api_hash=api_hash, skip_connect=True
        )

        logger.info(
            f"Validation result: success={validation.success}, tg_user_id={validation.tg_user_id}, error={validation.error}"
        )

        if not validation.success:
            item.error = validation.error
            return item

        item.tg_user_id = validation.tg_user_id  # –ú–æ–∂–µ—Ç –±—ã—Ç—å None ‚Äî —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
        item.username = validation.username
        item.phone = validation.phone

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–∞ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å tg_user_id)
        if validation.tg_user_id:
            existing = await check_duplicate(db_session, validation.tg_user_id)
            if existing:
                item.error = f"–î—É–±–ª–∏–∫–∞—Ç (ID: {existing.id})"
                item.is_duplicate = True
                return item

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å —Ö—Ä–∞–Ω–µ–Ω–∏—è:
        # - –ï—Å–ª–∏ –µ—Å—Ç—å tg_user_id: storage/sessions/{tg_user_id}/
        # - –ï—Å–ª–∏ –Ω–µ—Ç: storage/sessions/pending_{uuid}/
        if validation.tg_user_id:
            storage_id = str(validation.tg_user_id)
        else:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π ID –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è
            import uuid as uuid_module

            storage_id = f"pending_{uuid_module.uuid4().hex[:8]}"
            logger.info(f"No user_id, using temporary storage: {storage_id}")

        final_dir = os.path.join(SESSIONS_DIR, storage_id)
        os.makedirs(final_dir, exist_ok=True)
        final_path = os.path.join(final_dir, "account.session")

        shutil.copy2(session_path, final_path)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º api_id/api_hash —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –∏–∑ JSON
        save_api_id = api_id if item.api_source == "json" else None
        save_api_hash = api_hash if item.api_source == "json" else None

        # Fingerprint –∏–∑ validation —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        fp = validation.fingerprint

        # –°–æ–∑–¥–∞—ë–º –∞–∫–∫–∞—É–Ω—Ç
        account = Account(
            tg_user_id=validation.tg_user_id,
            username=validation.username,
            phone=validation.phone,
            storage_type=StorageType.TELETHON_SESSION,
            session_path=final_path,
            status=AccountStatus.FREE,
            is_premium=validation.is_premium,
            api_id=save_api_id,
            api_hash=save_api_hash,
            device_model=fp.device_model if fp else None,
            system_version=fp.system_version if fp else None,
            app_version=fp.app_version if fp else None,
            lang_code=fp.lang_code if fp else None,
            system_lang_code=fp.system_lang_code if fp else None,
            error_text=None,
        )
        db_session.add(account)
        await db_session.flush()
        await db_session.refresh(account)

        item.account_id = account.id
        item.success = True

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–∑–Ω–∞—á–∞–µ–º –ø—Ä–æ–∫—Å–∏
        assigned_proxy = await proxy_service.assign_proxy_to_account(
            db_session, account.id
        )
        if assigned_proxy:
            logger.info(
                f"Auto-assigned proxy {assigned_proxy.id} to account {account.id}"
            )

        user_id_status = (
            validation.tg_user_id or "pending (–±—É–¥–µ—Ç –ø–æ–ª—É—á–µ–Ω –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏)"
        )
        phone_status = validation.phone or "pending"
        logger.info(
            f"Batch import: account #{account.id} created, "
            f"tg_user_id={user_id_status}, phone={phone_status}, api_source={item.api_source}"
        )

        return item

    except Exception as e:
        logger.exception(f"Error importing session {session_path}: {e}")
        item.error = str(e)
        return item


async def import_zip(
    db_session: AsyncSession, zip_data: bytes, original_filename: str
) -> BatchImportReport:
    """
    –ò–º–ø–æ—Ä—Ç –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–µ—Å—Å–∏–π –∏–∑ ZIP-–∞—Ä—Ö–∏–≤–∞.

    Args:
        db_session: SQLAlchemy async session
        zip_data: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ ZIP-–∞—Ä—Ö–∏–≤–∞
        original_filename: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞

    Returns:
        BatchImportReport —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    """
    ensure_directories()
    report = BatchImportReport()

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
    if len(zip_data) > MAX_ZIP_SIZE:
        report.errors = 1
        report.items.append(
            SessionImportItem(
                session_path="",
                session_name="",
                success=False,
                error=f"ZIP —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (–º–∞–∫—Å. {MAX_ZIP_SIZE // 1024 // 1024} MB)",
            )
        )
        return report

    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—É—Ç–∏
    temp_id = str(uuid.uuid4())
    zip_path = os.path.join(INBOX_DIR, f"{temp_id}.zip")
    extract_dir = os.path.join(INBOX_DIR, f"batch_{temp_id}")

    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º ZIP
        os.makedirs(INBOX_DIR, exist_ok=True)
        with open(zip_path, "wb") as f:
            f.write(zip_data)

        logger.info(f"ZIP saved: {zip_path}, size: {len(zip_data)} bytes")

        # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º
        success, error = extract_zip(zip_path, extract_dir)
        if not success:
            report.errors = 1
            report.items.append(
                SessionImportItem(
                    session_path="", session_name="", success=False, error=error
                )
            )
            return report

        # –ò—â–µ–º .session —Ñ–∞–π–ª—ã
        session_files = find_session_files(extract_dir)
        report.total_sessions_found = len(session_files)

        if not session_files:
            report.errors = 1
            report.items.append(
                SessionImportItem(
                    session_path="",
                    session_name="",
                    success=False,
                    error="–í –∞—Ä—Ö–∏–≤–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ .session —Ñ–∞–π–ª–æ–≤",
                )
            )
            return report

        logger.info(f"Found {len(session_files)} session files in ZIP")

        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —Å–µ—Å—Å–∏—é
        for session_path in session_files:
            # –ò—â–µ–º JSON —Å credentials
            json_path = find_matching_json(session_path)
            api_id = None
            api_hash = None
            api_source = "none"

            if json_path:
                creds = extract_api_credentials(json_path)
                if creds:
                    api_id, api_hash = creds
                    api_source = "json"
                    logger.info(
                        f"Found credentials for {session_path}: api_id={api_id}"
                    )

            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º
            item = await import_one_session(
                db_session,
                session_path,
                api_id=api_id,
                api_hash=api_hash,
                api_source=api_source,
            )

            if item.success:
                report.add_success(item)
            else:
                report.add_error(item)

        return report

    except Exception as e:
        logger.exception(f"Batch import error: {e}")
        report.errors += 1
        report.items.append(
            SessionImportItem(
                session_path="",
                session_name="",
                success=False,
                error=f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}",
            )
        )
        return report

    finally:
        # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        try:
            if os.path.exists(zip_path):
                os.remove(zip_path)
            if os.path.exists(extract_dir):
                shutil.rmtree(extract_dir, ignore_errors=True)
            logger.info("Temporary files cleaned up")
        except Exception as e:
            logger.warning(f"Failed to cleanup temp files: {e}")
